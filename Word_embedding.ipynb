{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z4Mmk5I8v1v",
        "outputId": "18945557-ab5d-4e92-e0f2-b2feb8d26f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_3Y7IEu_IhD",
        "outputId": "171b5324-86bb-4134-bbcd-fcb12e2b9987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ICU-Tokenizer\n",
            "  Downloading icu_tokenizer-0.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from ICU-Tokenizer) (4.64.1)\n",
            "Collecting PyICU\n",
            "  Downloading PyICU-2.10.2.tar.gz (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from ICU-Tokenizer) (2022.6.2)\n",
            "Building wheels for collected packages: ICU-Tokenizer, PyICU\n",
            "  Building wheel for ICU-Tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ICU-Tokenizer: filename=icu_tokenizer-0.0.1-py3-none-any.whl size=13280 sha256=d4c1688a8956d33f78469800435891b98e8875a7daf5e99b9f31393ef6905405\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/a2/a9/b6414263fa62b478a0bac882d8ad7801018fd6c6cb4b32f6ed\n",
            "  Building wheel for PyICU (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyICU: filename=PyICU-2.10.2-cp38-cp38-linux_x86_64.whl size=1396697 sha256=472230825602ca44d825db3b5b68eb85d81b952245185ee5f0ee3f6f039a73df\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/30/74/41fd0a7e2e17f8f92d5a4584c2aad30d8235c8cfa63a13742f\n",
            "Successfully built ICU-Tokenizer PyICU\n",
            "Installing collected packages: PyICU, ICU-Tokenizer\n",
            "Successfully installed ICU-Tokenizer-0.0.1 PyICU-2.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ICU-Tokenizer\n",
        "from icu_tokenizer import Tokenizer\n",
        "tokenizer = Tokenizer(lang='bengli')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH2wqpd_81b-",
        "outputId": "62684965-9cea-4cf5-f9c2-2b8459c44413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3.5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "from pprint import pprint\n",
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-IPBwZl9S3X"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/Data_set/preprocess data/filename.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rp2QcjK9MOv"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for text in test['finalsummery']:\n",
        "  words = [word for word in tokenizer.tokenize(text)]\n",
        "  corpus.append(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "au3LkOtDRRhB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1qzp1_yM9FR"
      },
      "source": [
        "# Fasttxt Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER3l4y2Wyzyi"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "model_ted = FastText(corpus, size=100, window=5, min_count=5, workers=4,sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq9mwaAghzCR"
      },
      "outputs": [],
      "source": [
        "model_ted.save('/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjzXahnNiGMY",
        "outputId": "b9f1c2b3-11d2-4872-f951-724916809620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d546e406023b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodelpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \"\"\"\n\u001b[1;32m    935\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vectors_vocab_lockf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vectors_vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_vocab_lockf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \"\"\"\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ns_exponent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mns_exponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseAny2VecModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \"\"\"\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mso_compression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFER_FROM_EXTENSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim'"
          ]
        }
      ],
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "modelpath = '/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim'\n",
        "model = FastText.load(modelpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm_FAHb23r3S"
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "modelpath = '/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim2'\n",
        "model2 = FastText.load(modelpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEXMofLeGD7T",
        "outputId": "29da3f16-69aa-4f7b-cee1-ba7d7f53f463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ও', 0.710696816444397),\n",
              " ('।', 0.662300705909729),\n",
              " ('‘', 0.6393415927886963),\n",
              " ('এবং', 0.6067748069763184),\n",
              " ('নাদেলের', 0.5612422227859497),\n",
              " ('দেলওয়ার', 0.5609130859375),\n",
              " ('‑', 0.5408311486244202),\n",
              " ('বলেন', 0.5379682779312134),\n",
              " ('নাদেল', 0.537921667098999),\n",
              " ('বায়জীদ', 0.5317046642303467)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.most_similar(\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzQQZhWs3v60",
        "outputId": "967378b7-9b3e-41f5-9321-9c714600153f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('”', 0.7188056707382202),\n",
              " ('ইয়ুথ', 0.6466854810714722),\n",
              " ('ইয়েট', 0.6423752307891846),\n",
              " ('সিনক্লেয়ার', 0.6392045021057129),\n",
              " ('স্টাডিতে', 0.6376911401748657),\n",
              " ('ডিবেট', 0.6371051073074341),\n",
              " ('এমফিথিয়েটারে', 0.6349629759788513),\n",
              " ('থিয়েটার', 0.6333267688751221),\n",
              " ('মেরিডিয়ান', 0.6329158544540405),\n",
              " ('এনভায়রনমেন্টাল', 0.6310501098632812)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.wv.most_similar(\"!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvKH2MvAk9l4",
        "outputId": "368289f7-c47c-46e3-efdf-2cb4569452a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.fasttext.FastText at 0x7f725d9a2990>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYCf0OvZM2Sy"
      },
      "source": [
        "# Glove Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRc74V8cMAPT"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"corpus.txt\", corpus, delimiter=\", \", fmt=\"% s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_q9cdneMARF"
      },
      "outputs": [],
      "source": [
        "model_ted.save('/content/drive/MyDrive/Data_set/pre-trained model/Fasttext/saved_model_gensim')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUF4iqqPMOqE"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/corpus.txt\" \"/content/glove\"\n",
        "\n",
        "# BUt if you still want to move them not copy , Here's solution for that :\n",
        "# !mv \"/content/corpus.txt\" \"/content/glove\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bLJIM1bMRP6"
      },
      "outputs": [],
      "source": [
        "!git clone http://github.com/stanfordnlp/glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14YFmvR8MRTZ"
      },
      "outputs": [],
      "source": [
        "%cd glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWTZso8_MVS2"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RSaVOA_MjPu"
      },
      "source": [
        "corpus.txt should be exist in glove folder\n",
        "\n",
        "before run demo.sh edit the file->write corpus.txt in the place of text8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_m636MUMVZi"
      },
      "outputs": [],
      "source": [
        "!/content/glove/demo.sh\n",
        "# ! path/demo.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDrMQUGBMVbG"
      },
      "outputs": [],
      "source": [
        "test = pd.read_fwf('/content/drive/MyDrive/Data_set/pre-trained model/Glove/corpus.txt')\n",
        "pprint(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK8iFHg7yJXq",
        "outputId": "52ed26b9-4c18-4e22-cf58-1be7e478a536"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb3HnkvwXVQT"
      },
      "source": [
        "# TF word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDvB_HFIXjGT",
        "outputId": "947c209f-235f-45c2-be07-b79f50fa6c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 48.3474\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 48.1884\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 48.0289\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 47.8623\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 47.6821\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 47.4819\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 47.2549\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 46.9943\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 46.6935\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 46.3467\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 6, 128)            1280      \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,638\n",
            "Trainable params: 133,638\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Preprocess the data\n",
        "# vocab_size = 10000  # Size of the vocabulary\n",
        "word_sequences = [[\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"], [\"the\", \"dog\", \"barked\", \"at\", \"the\", \"mailman\"]]\n",
        "labels = [[\"cat\", \"sat\", \"on\", \"the\", \"mat\", \".\"], [\"dog\", \"barked\", \"at\", \"the\", \"mailman\", \".\"]]\n",
        "\n",
        "# Create a mapping from words to integers\n",
        "word_index = {}\n",
        "for seq in word_sequences:\n",
        "    for word in seq:\n",
        "        if word not in word_index:\n",
        "            word_index[word] = len(word_index)\n",
        "\n",
        "# # Create a mapping from integers to words\n",
        "# index_word = {index: word for word, index in word_index.items()}\n",
        "word_index[\"<UNK>\"] = len(word_index)\n",
        "index_word = {index: word for word, index in word_index.items()}\n",
        "vocab_size = len(word_index)\n",
        "\n",
        "# # Create the input and label data\n",
        "# X = [[word_index[word] for word in seq] for seq in word_sequences]\n",
        "# Y = [[word_index[word] for word in seq] for seq in labels]\n",
        "\n",
        "X = [[word_index.get(word, word_index[\"<UNK>\"]) for word in seq] for seq in word_sequences]\n",
        "Y = [[word_index.get(word, word_index[\"<UNK>\"]) for word in seq] for seq in labels]\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=128, input_length=6))\n",
        "model.add(tf.keras.layers.LSTM(128))\n",
        "model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, batch_size=32, epochs=10)\n",
        "model.summary()\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ry2UD_X4AUK",
        "outputId": "705b4b11-f64e-4c4d-e44d-68999b1b694f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 432ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.13929088, 0.16535972, 0.16941279, 0.1312256 , 0.1702401 ,\n",
              "        0.22447091],\n",
              "       [0.13603178, 0.17063949, 0.17425424, 0.12578954, 0.17132857,\n",
              "        0.22195631]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6nh1pGJTgTLF",
        "outputId": "455efe0e-db8e-4e9a-a55f-6d62a262c7e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 6) for input KerasTensor(type_spec=TensorSpec(shape=(None, 6), dtype=tf.float32, name='embedding_14_input'), name='embedding_14_input', description=\"created by layer 'embedding_14_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 460ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e26b913dbdd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Compute the cosine similarity between the two embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdog_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_embedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (1,6) and (1,6) not aligned: 6 (dim 1) != 1 (dim 0)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate embeddings for the word \"cat\"\n",
        "cat_embedding = model.predict(np.array([[word_index[\"cat\"]]]))\n",
        "\n",
        "# Generate embeddings for the word \"dog\"\n",
        "dog_embedding = model.predict(np.array([[word_index[\"dog\"]]]))\n",
        "\n",
        "# Compute the cosine similarity between the two embeddings\n",
        "similarity = np.dot(cat_embedding, dog_embedding) / (np.linalg.norm(cat_embedding) * np.linalg.norm(dog_embedding))\n",
        "print(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY1OePa-pDiZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}